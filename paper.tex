\documentclass[12pt,psamsfonts]{article}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{blkarray}
\usepackage{upquote}
\usepackage{tikz}
\usepackage{bbm}
\usepackage{url}
\usepackage{tikz-cd}
\usepackage{enumerate}

\newcommand{\deriv}[2]{\frac{\mathrm{d}#1}{\mathrm{d}#2}}
\newcommand{\pderiv}[2]{\frac{\partial #1}{\partial #2}}
\DeclareMathOperator{\spn}{span}
\DeclareMathOperator{\stab}{stab}
\DeclareMathOperator{\ord}{ord}
\DeclareMathOperator{\Ind}{Ind}
\DeclareMathOperator{\Res}{Res}
\DeclareMathOperator{\Image}{Image}
\DeclareMathOperator{\cof}{cof}
\DeclareMathOperator{\lcm}{lcm}
\DeclareMathOperator{\real}{Re}
\DeclareMathOperator{\arccot}{arccot}
\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\atan2}{atan2}
\DeclareMathOperator{\interior}{int}
\DeclareMathOperator{\Br}{Br}
\DeclareMathOperator{\End}{End}
\DeclareMathOperator{\Aut}{Aut}
\DeclareMathOperator{\Gal}{Gal}
\DeclareMathOperator{\inv}{inv}
\DeclareMathOperator{\GL}{GL}
\DeclareMathOperator{\SL}{SL}
\DeclareMathOperator{\gl}{\mathfrak{gl}}
\DeclareMathOperator{\spl}{\mathfrak{sl}}
\DeclareMathOperator{\ad}{ad}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\newcommand{\opp}{\mathrm{opp}}
\newcommand{\un}{\mathrm{un}}
\newcommand{\al}{\mathrm{al}}
\newcommand{\dd}{\mathrm{d}}
\newcommand{\comment}{}

\usepackage[capitalize,nameinlink,noabbrev]{cleveref} % to emulate \autoref style


\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{corollary}[theorem]{Corollary}
% \newcommand{\theoremautorefname}{Theorem}
\newcommand{\lemmaautorefname}{Lemma}
\newcommand{\definitionautorefname}{Definition}

\bibliographystyle{plain}
\usepackage{nicematrix}

% \author{Owen Conoly}
% \date{Date}
% \title{Title}

\begin{document}

% \maketitle
\section{Definition of one thing}
Let \(G \subseteq \GL_m(\mathbb{C})\) be a connected semisimple Lie group, and let \(\mathfrak{g} \subseteq \gl_m(\mathbb{C})\) be its Lie algebra.
% ^I take this scope because it is about what Yuzhou Gu said.
Let \(\mathcal{N} \subseteq \mathfrak{g}\) be the subset consisting of nilpotent elements.
Let \(\mathcal{B}\) be the variety of Borel subalgebras of \(\mathfrak{g}\).
Let \(\widetilde{\mathcal{N}} = \{(\mathfrak{b}, n) : n \in \mathfrak{b}\} \subseteq \mathcal{B} \times \mathcal{N}\).
Let \(\pi : \widetilde{\mathcal{N}} \to \mathcal{N}\) be the projection onto the second coordinate.
For \(n \in \mathcal{N}\), we call \(\pi^{-1}(n)\) the \emph{Springer fiber at \(n\)}.

\section{Slodowy slice}
A basis for \(\spl_2(\mathbb{C})\) is
\[e' := \begin{pmatrix}0 & 1 \\ 0 & 0 \\\end{pmatrix}, h' := \begin{pmatrix}1 & 0 \\0 & -1\end{pmatrix}, f' := \begin{pmatrix}0 & 0 \\1 & 0\end{pmatrix}.\]
Given a Lie algebra \(\mathfrak{g}\), and a homomorphism \(\phi : \spl_2 \to \mathfrak{g}\) sending \((e', h', f')\) to \((e, h, f)\), we say that \((e, h, f)\) is an \emph{\(\spl_2\)-triple}.
Observe that \(e, f\) must be nilpotent, and \(h\) must be Cartan (???).
If \(\mathfrak{g}\) is semisimple, then given any nilpotent \(e \in \mathfrak{g}\), the Jacobson-Morozov theorem \cite[3.7.1]{ehf} says that there exist \(h, f \in \mathfrak{g}\) such that \((e, h, f)\) is an \(\spl_2\)-triple.
\par Given \((e, h, f)\), we define the \emph{Slodowy slice at \(e\)} as \(\mathcal{S}_e := e + \ker \ad_f\).
By the Jacobson-Morozov theorem, we can always find a Slodowy slice at any nilpotent \(e \in \mathfrak{g}\), when \(\mathfrak{g}\) is semisimple.

\subsection{Finding an \(\spl_2\)-triple in a simple case}
\par Let
\[e = \begin{pNiceArray}{ccccc}
 0 \\
    1 & 0 \\
  & 1 & \ddots \\
   & & \ddots & 0 \\
   &   &  & 1 & 0
   \end{pNiceArray} \in \mathfrak{sl}_{n},\]
where there are \(n - 1\) ones.
We will find the Slodowy slice at \(e\).
\par As a first step, we will find an \(\spl_2\)-triple with \(e\) as its first element.
Note that \([h', e'] = 2e'\), and \([e', f'] = h'\), and \([h', f'] = -2f'\).
Thus \(e, h, f\) must obey the same relations.
In particular, \(he - eh = 2e\).  
The matrix \(eh\) is \(h\) shifted down one, and \(he\) is \(h\) shifted left one.
Thus, \(2e_{ij} = (he - eh)_{ij} = h_{i, j + 1} - h_{i - 1, j}\).
We can use this to show that \(h_{ij} = 0\) when \(i \neq j\).
Then we can use it to show that \(h_{ii} = h_{i - 1, i - 1} + 2\), so that \(h_{ii} = h_{11} + 2(i - 1)\).
\par Similarly, from \([e, f] = h\) we get that \(h_{ij} = (ef - fe)_{ij} = f_{i - 1, j} - f_{i, j + 1}\).
We can use this to show that \(f_{ij} = 0\) when \(j \neq i + 1\).
Then we can use it to show that \(f_{i,i + 1} = f_{i + 1, i + 2} + h_{i + 1, i + 1}\), that \(f_{1,2} = -h_{1, 1}\), and that \(f_{n - 1, n} = h_{n,n}\).
From the first equation we find that
\[-h_{1,1} = f_{1, 2} = f_{n - 1, n} + \sum_{i = 1}^{n - 1} h_{ii} = \sum_{i = 1}^{n} h_{ii} \implies\]
\[\sum_i h_{ii} = 0.\]
Oops, I didn't actually need to prove that, since \(h \in \spl_n\)... it's nice to know that it's the unique solution in \(\gl_n\) though?
This shows that \(h_{11} = n - 1, h_{22} = n - 3, ..., h_{nn} = 1 - n\).
So we have determined \(h\); it is 
\[h = \begin{pmatrix}
    n - 1  & \\
    & n - 3 \\
    & & \ddots \\
    & & & 3 - n \\
    & & & & 1 - n 
\end{pmatrix}.\]
Now, we can use our expression for \(f\) in terms of \(h\) to obtain
\[f = \begin{pmatrix}
    0 & 1 - n \\
    & 0 & (1 - n) + (3 - n) \\
    & & \ddots & \ddots \\
    & & & 0 & (1 - n) + \cdots + (n - 1) \\
    & & & & 0
\end{pmatrix} = \]
\[\begin{pmatrix}
    0 & 1 (1 - n) \\
      & 0 & 2 (2 - n) \\
    & & 0 & (n - 2) (-2) \\
    & & & 0 & (n - 1) (-1)\\
    & &  & & 0
\end{pmatrix}.\]

\subsection{Finding an \(\spl_2\)-triple in a slightly less simple case}
Now, let 
\[E = \begin{pmatrix}
    0 & 0 \\
    0 & e
\end{pmatrix} \in \spl_{m + n},\]
with \(e\) as in the previous subsection.
We will find \(H, F\) so that \((E, H, F)\) is an \(\spl_2\)-triple.
Writing \(F = \begin{pmatrix}
    F_{11} & F_{12} \\
    F_{21} & f
\end{pmatrix}\), and similarly for \(H\), we have
\[2E = [H, E] = \begin{pmatrix}
    0 & H_{12}e \\
    0 & he
\end{pmatrix} - \begin{pmatrix}
    0 & 0 \\
    e H_{21} & eh
\end{pmatrix},\]
\[H = [E, F] = \begin{pmatrix}
    0 & 0 \\
    e F_{21} & ef
\end{pmatrix} - \begin{pmatrix}
    0 & F_{12}e \\
    0 & fe
\end{pmatrix}.\]
From these we observe that \((e, h, f)\) must also be an \(\spl_2\)-triple, so \(h, f\) must be as in the previous subsection.
We also see that \(H_{11} = 0\).
Recalling that left multiplication by \(e\) is a down-shift, and right multiplication is a left-shift, we see that \(H_{12}\) is all zeroes except for the leftmost column, and \(H_{21}\) is all zeroes except for the bottom row.
% Then \(F_{12}\) must be all zeros except for the two leftmost columns, and \(F_{21}\) must be all zeroes except for the bottom two rows.
Then our final constraint is that 
\[-2F = [H, F] = \]
\[\begin{pmatrix}
    H_{12} F_{21} & H_{12} F_{22} \\
    H_{21} F_{11} + H_{22} F_{21} & H_{21} F_{12} + H_{22} F_{22}
\end{pmatrix} - \begin{pmatrix}
    F_{12} H_{21} & F_{11} H_{12} + F_{12} H_{22} \\
    F_{22} H_{21} & F_{21} H_{12} + F_{22} H_{22}
\end{pmatrix}.\]
Now \(H_{12} = F_{12}e\), and \(H_{21} = eF_{21}\), from the equation \(H = [E, F]\).
Substituting in the equation above then,
\[-2F = \begin{pmatrix}
    F_{12} e F_{21} & F_{12}e f \\
    eF_{21} F_{11} + h F_{21} & eF_{21} F_{12} + hf
\end{pmatrix} - \begin{pmatrix}
    F_{12} e F_{21} & F_{11} F_{12}e + F_{12} h \\
    f eF_{21} & F_{21} F_{12}e + fh
\end{pmatrix} =\]
\[\begin{pmatrix}
    0 & F_{12}(fe + h) \\
    eF_{21} F_{11} + h F_{21} & eF_{21} F_{12} + hf
\end{pmatrix} - \begin{pmatrix}
    0 & F_{11} F_{12}e + F_{12} h \\
    (ef - h)F_{21} & F_{21} F_{12}e + fh
\end{pmatrix} =\]
\[\begin{pmatrix}
    0 & F_{12}fe \\
    eF_{21} F_{11} & eF_{21} F_{12} + hf
\end{pmatrix} - \begin{pmatrix}
    0 & F_{11} F_{12}e \\
    ef F_{21} & F_{21} F_{12}e + fh
\end{pmatrix}.\]
Now we see that \(F_{11} = 0\), and consequently that \(F_{12} = F_{21} = 0\) as well.
This shows that \(H_{12} = H_{21} = 0\).
We conclude that \(H\) and \(F\) just have \(h\) and \(f\) in their bottom-right corners, respectively.

\section{Definition of springer fiber at slodowy slice}
% Explain why these are Springer fibers at Slodowy slices.
\par Let \(\mathcal{N}_m \subseteq \gl_m(\mathbb{C})\) be the subset consisting of nilpotent elements.
For \(X \in \mathcal{N}\) and \(a, b \in \mathbb{C}^m\), let
\[A_{X, a, b} = \begin{pNiceArray}{ccc|ccccc}
 & & & & & & & \vert \\
 & X & & & & & & b    \\
 & & & & & & & \vert \\
\hline
\text{---} & a & \text{---} & 0 \\
& & & 1 & 0 \\
& & &  & 1 & \ddots \\
& & &  &   & \ddots & 0 \\
& & &  &   &  & 1 & 0
\end{pNiceArray} \in \mathfrak{gl}_{m + n}(\mathbb{C}).\]

% \par Note that \(X \mapsto A_{X, a, b}\) gives a map \(\gl_m(\mathbb{C}) \to \gl_{m + n}(\mathbb{C})\).
Let \(\mathcal{M}\) be the variety of Borel subalgebras of \(\gl_{m + n}(\mathbb{C})\).
Let
\[\widetilde{\mathcal{N}} = \{(\mathfrak{m}, a, b, X) : A_{X, a, b} \in \mathfrak{m}\} \subseteq \mathcal{M} \times \mathbb{C}^m \times \mathbb{C}^m \times \mathcal{N}.\]
Let \(\pi : \widetilde{\mathcal{N}} \to \mathcal{N}\) be the projection onto the last coordinate.
For \(X \in \mathcal{N}\), we call \(\pi^{-1}(X)\) the \emph{other Springer fiber at \(X\)}.
\section{Finding the Springer fibers of section 2}
We have \(\mathcal{M} = \{AHA^{-1} : A \in \GL_{m + n}(\mathbb{C})\}\), where \(H \subseteq \gl_{m + n}(\mathbb{C})\) is the set of upper triangular matrices.
We say a map \(X : \gl_{m + n} \to \gl_{m + n}\) preserves a flag \(V_0 \subseteq \cdots \subseteq V_{m + n}\) if \(XV_i \subseteq V_i\) for each \(i\).
Let \(E_0 \subseteq \cdots \subseteq E_{m + n}\) be the standard flag of \(\mathbb{C}^{m + n}\).
Since \(H\) is the set of \(X\) which preserve \(E\),
\[\mathcal{M} = \{\{X : \forall i. \; X(AE_i) \subseteq AE_i\} : A \in \GL_n(\mathbb{C})\}.\]
So, for \(X \in \mathcal{N}\),
\[\pi^{-1}(X) \cong \{(V, a, b) : \forall i. \; A_{X, a, b} V_i \subseteq V_i\}.\]
\par In this section we will find the irreducible components of \(\pi^{-1}(X)\).
Since \(\pi^{-1}(X) \cong \pi^{-1}(AXA^{-1})\) for any invertible \(A\), we will assume that \(X\) is in Jordan normal form.
\par Let \(\lambda\) be the shape of \(X\), and let \((e_{ij})_{i \leq r, j \leq \lambda_i}\) be a Jordan basis for \(X\), with \(X e_{ij} = e_{i,j - 1}\).
Let \(f_1, ..., f_n\) be the standard basis for \(\mathbb{C}^n\), with \(A_{X, a, b} f_i = f_{i + 1}\).

\subsection{A necessary condition for \(A_{X, a, b}\) to be nilpotent}
Suppose \(A := A_{X, a, b}\) is nilpotent.
Define the \emph{height} of a vector \(v \in \mathbb{C}^{m + n}\) as the smallest \(k \geq 0\) such that \(A_{X, a, b}^k v = 0\).
Clearly, for \(i \leq j\), we have that the height of \(f_i\) is geq the height of \(f_j\).
Thus, for each \(k \geq 0\), we must have \(A_{X, a, b}^k f_n \in \langle e_{ij} \rangle_{ij}\).
We have \(Af_n = \sum_{ij} b_{ij} e_{ij}\).
Then \(A^2 f_n = \sum_{ij} b_{ij} (e_{i, j - 1} + a_{ij} f_1)\), so we must have \(\sum_{ij} b_{ij} a_{ij} = 0\).
Similarly, since \(A^3 f_n \in \langle e_{ij}\rangle\), we see that \(\sum_{ij} b_{ij} a_{i, j - 1} = 0\).
Continuing in this way, we obtain that for all \(k \geq 0\),
\begin{equation}\label{ab_nilp}\sum_{ij} b_{ij} a_{i,j - k} = 0.\end{equation}
In fact this is in fact a sufficient condition for \(A_{X, a, b}\) to be nilpotent, as can be seen from the characteristic polynomial of \(A_{X, a, b}\).
However, we will not do this calculation here, instead just showing that it is sufficient by giving a Jordan basis.

\subsection{When \(X\) is all zeroes}
In this case we have \(A(y, z) = (z_n b, (a \cdot y, z_1, ..., z_{n - 1}))\), and the condition becomes
\[\sum_i b_i a_i = 0.\]
In this case we will be able to write down explicitly the irreducible components of \(F := \{(V, a, b) : \forall i. \; A_{X, a, b} V_i \subseteq V_i\} \cong \pi^{-1}(X)\).
For any nonnegative \(\delta_0, \delta_1, ..., \delta_n, \delta_{n + 1}\) summing to \(m\), define the corresponding sequence \(i_0 = \delta_0\), \(i_n = \delta_{n + 1} + i_n\), and for \(j \in \{1, ..., n\}\), \(i_j = i_{j - 1} + 1 + \delta_j\).
Let \(E\) be the span of the \(e_i\)'s, and let \(E' = \{(x, 0) \in E : x \cdot a = 0\}\), where the dot is the \(m\)-dimensional dot product.
Then define \(F_\delta\) as the set of \((V, a, b) \in F\) such that 
\begin{itemize}
    \item \(b \in V_{i_0} \subseteq E'\)
    \item for all \(j \in \{1, ..., n\}\), we have \(f_j \in V_{i_j} \subseteq E' + \langle f_1, ..., f_j \rangle\)
\end{itemize}
I claim that the \(F_\delta\)'s are the irreducible components of \(F\).
To begin, I show that their union is \(F\).

\begin{lemma}
    Let \((V, a, b) \in \mathcal{F}\).
    Write \(f_0 = b\), and \(F = \langle f_0, f_1, ..., f_n \rangle\).
    For each \(i\), either \(F \subseteq V_i\), or else there exists \(j\) such that \(e_j \notin V_i\), but \(\langle e_0, ..., e_{j - 1} \rangle \subseteq V_i \subseteq E' + \langle e_1, ..., e_j \rangle\).
\end{lemma}
\begin{proof}
    For \(i = 0\), we may take \(j = 0\).
    Now assume the statement holds for \(i\), and we will prove it for \(i + 1\).
    If \(F \subseteq V_i\), then \(F \subseteq V_{i + 1}\), and we are done.
    \par So, suppose there is \(j\) such that \(e_j \notin V_i\), but \(\langle e_0, ..., e_{j - 1} \rangle \subseteq V_i \subseteq E' + \langle e_0, ..., e_j \rangle\).
    We have two cases: either \(V_{i + 1} = V_i + \langle e_j \rangle\), or not.
    \begin{itemize}
        \item If so, then either \(j = n\), in which case \(F \subseteq V_{i + 1}\), or else \(j \neq n\), in which case \(e_{j + 1} \notin V_{i + 1}\), but \(\langle e_0, ..., e_j \rangle \subseteq V_{i + 1} \subseteq E' + \langle e_0, ..., e_{j + 1} \rangle\).
        \item If not, then \(e_j \notin V_{i + 1}\).
        Let \(v_{i + 1}\) be so that \(V_{i + 1} = V_i + \langle v_{i + 1} \rangle\).
        I just need to show that \(v_{i + 1} \in Y + \langle e_1, ..., e_j \rangle\).
        It suffices to show that \(v_{i + 1}^\top e_k = 0\) for \(k > j\).
        And to do this, it suffices to show that \((Av_{i + 1})^\top e_{k - 1} = 0\) for \(k > j\).
        \par Note that \(Av_{i + 1} \in V_i \cap A \mathbb{C}^{2n} \subseteq \langle e_1, ..., e_j \rangle\).
        So, for \(k > j + 1\) it is clear that \((Av_{i + 1})^\top e_{k - 1} = 0\).
        Now, suppose for contradiction that \((Av_{i + 1})^\top e_j \neq 0\).
        Then \(Av_{i + 1}\) is linearly independent of \(e_1, ..., e_{j + 1}\).
        Since \(Av_{i + 1} \in \langle e_1, ..., e_j \rangle\), it follows that \(e_j \in \langle e_1, ..., e_{j - 1}, Av_{i + 1} \rangle \subseteq V_i\), a contradiction.
    \end{itemize}
\end{proof}

\begin{corollary}
    \(\mathcal{F} = \bigcup_\delta \mathcal{F}_\delta\)
\end{corollary}
\begin{proof}
    Let \((V, a, b) \in F\).
    Let \(i_0 = \min\{i : b \in V_i\}\), and let \(i' = \max\{i : V_i \subseteq E'\}\).
    We want that \(b \in V_{i_0} \subseteq E'\), so we want that \(i_0 \leq i'\).
    For contradiction, suppose \(i' < i_0\).

\end{proof}

\begin{lemma}
    Each \(\mathcal{F}_\delta\) is a closed subvariety of \(\mathcal{F}\).
\end{lemma}
\begin{proof}
    
\end{proof}

\begin{lemma}
    Each \(\mathcal{F}_\delta\) is irreducible of dimension \(m\).
\end{lemma}
\begin{proof}
    Let \(\mathcal{E}\) be the variety of partial flags of \(E\) of shape \((\delta_0, ..., \delta_{n + 1})\).
    Define \(g : \mathcal{F}_\delta \to \mathcal{E}\) by
    \[(V, a, b) \mapsto 0 \subseteq V_{i_0} \cap E \subseteq V_{i_1} \cap E \subseteq \cdots \subseteq V_{i_{n + 1}} \cap E = E.\]
    It is clear that \(g\) is surjective, as the definition of \(\mathcal{F}_\delta\) places no restriction on the intersections \(V_i \cap E\).
    Now let's look more closely at the fibers \(g^{-1}(U)\).
    \par First let's find the flags \(V\) such that there exist \(a, b\) with \(g(V, a, b) = U\).
    We see that, for instance, \(V_{i_0} \cap E = U_1\).
    In fact \(V_{i_0} \subseteq E\), so \(V_{i_0} = U_1\).
    But we are free to choose the vector spaces between \(0\) and \(V_{i_0}\) however we wish, so we get some degrees of freedom like \(\mathcal{F}_{\delta_0}\), the complete flag variety on \(\mathbb{C}^{\delta_0} \cong V_{i_0} / 0\).
    Similarly, for every \(j = 1, ..., n + 1\), we can choose the vector spaces between \(V_{i_{j - 1}}\) and \(V_{i_j}\) arbitrarily, so we get degrees of freedom like \(\mathcal{F}_{\delta_{i_j}}\), the complete flag variety on \(\mathbb{C}^{\delta_{i_j}} \cong V_{i_j} / V_{i_{j - 1}}\).
    Finally, to meet the constraint of \((V, a, b)\) being in \(\mathcal{F}_\delta\), we can choose any \(b \in U_1\) and any \(a\) such that \(\overline{a} \in U_n^\perp\).
    Thus we get an isomorphism
    \[g^{-1}(U) \cong \mathcal{F}_{\delta_0} \times \cdots \times \mathcal{F}_{\delta_{n + 1}} \times \mathbb{C}^{\delta_0} \times \mathbb{C}^{\delta_{n + 1}}.\]

\end{proof}

\begin{theorem}
    The \(\mathcal{F}_\delta\)'s are the irreducible components of \(\mathcal{F}\).
\end{theorem}

\subsection{When \(X\) is a Jordan block}
Suppose \(X\) is a single Jordan block of size \(m\).
In this case we just write the basis of \(\mathbb{C}^m\) as \(e_1, ..., e_m\), and the above condition on \(a\) and \(b\) simply becomes
\begin{equation}
    \forall k \geq 0. \; \sum_{i = k + 1}^m b_i a_{i - k} = 0.
\end{equation}
This condition can be simplified even more.
\begin{lemma}
    The condition (1) holds iff there exist nonnegative \(m_1, m_2, m_3\), \(a_1, ..., a_{m_3}\), and \(b_1, ..., b_{m_3}\) satisfying the following conditions.
    \begin{itemize}
        \item \(m = m_1 + m_2 + m_3\)
        \item \(a = (0, 0, ..., 0, a_1, ..., a_{m_3})\)
        \item \(b = (b_1, ..., b_{m_1}, 0, 0, ..., 0)\)
        \item If \(m_1 \neq 0\), then \(a_{m_1} \neq 0\)
        \item If \(m_3 \neq 0\), then \(b_1 \neq 0\)
    \end{itemize}
\end{lemma}
\begin{proof}
    If \(a\) and \(b\) are of this form, then for every \(k \geq 0\) we have \(b_i a_{i - k} = 0\), so clearly the condition holds.
    \par Now suppose (1) holds.
    If \(a\) or \(b\) is zero, this is trivial.
    Otherwise, let \(m_1 = \max\{i : a_i \neq 0\}\), and let \(m_3 = \min\{i : b_i \neq 0\}\).
    We just need to show that \(m_1 < m_3\).
    For contradiction, suppose \(m_1 - m_3\) is nonnegative.
    Then by (1), \(0 = \sum_i b_i a_{i - (m_1 - m_3)} = b_1 a_{m_1}\), contradicting that \(b_1\) and \(a_{m_1}\) are nonzero.
\end{proof}

\subsection{In the case of general \(X\)}
In the case where \(X\) was a single Jordan block, it was helpful to have the condition that all the nonzero \(a\)'s were to the right of all the nonzero \(b\)'s.
In the general case, it is not clear that such a thing should be true.
And indeed it is not.
However, we will see that we can change basis of \(\mathbb{C}^m\) so that a similar thing is true.
\par Let \(c_{i',j'}^i \in \mathbb{C}\) be some arbitrary coefficients.
Given our Jordan basis \(e_{ij}\) of \(\mathbb{C}^m\), we can define a new Jordan basis \(e_{ij}'\) of \(\mathbb{C}^m\) by 
\[e_{i, \lambda_i}' = e_{i, \lambda_i} + \sum_{\{(i',j') : i' \geq i\} \setminus \{(i, j)\}} c^i_{i',j'} e_{i',j'}.\]
Then we define
\[e_{i,j}' = X^{\lambda_i - j} e_{i, \lambda_i}' = e_{ij} + \sum_{\{(i', j') : i' \geq i\} \setminus \{(i, j)\}} c^i_{i',j'} e_{i', j' - (\lambda_i - j)}.\]
Let us calculate the new value \(a'\) of \(a\) in this new basis.
That is, we want the values \(a_{ij}'\) that satisfy \(Ae_{ij}' = e_{i, j - 1}' + a_{ij}' f_1\).
Looking at the definition of \(e_{ij}'\) above, we see that
\[a_{ij}' = a_{ij} + \sum_{\{(i',j') : i' \geq i\} \setminus \{(i, j)\}} c_{i',j'}^i a_{i', j' - (\lambda_i - j)}.\]
\par Now, for each \(i\), choose the coefficients \(c_{i',j'}^i\) to maximize the value \(\max\{j : (a_{i,1}', ..., a_{i, j}') = 0\}\).
In other words, we choose \(c_{i'j'}^i\) to zero out the largest possible prefix of \((a_{i, 1}, ..., a_{i, \lambda_i})\).
\begin{lemma}
    If the condition of \cref{ab_nilp} on \(a'\) and \(b'\) holds, then there exist nonnegative \(p_i, q_i, r_i\), \(\alpha_{i, j}\), \(\beta_{i, j}\) such that for each \(i\), the following conditions are satisfied.
    \begin{itemize}
        \item \(\lambda_i = p_i + q_i + r_i\)
        \item \((a_{i,1}', ..., a_{i,\lambda_i}') = (0, 0, ..., 0, \alpha_{i,1}, ..., \alpha_{i, r_i})\)
        \item \((b_{i, 1}', ..., b_{i, \lambda_i}') = (\beta_{i, 1}, ..., \beta_{i, p_i}, 0, 0, ..., 0)\)
        \item If \(r_i \neq 0\), then \(\alpha_{i,1} \neq 0\)
        \item If \(p_i \neq 0\), then \(\beta_{i, p_i} \neq 0\)
    \end{itemize}
\end{lemma}
\begin{proof}
    We begin with the first row of \(\lambda\), namely \(i = 1\).
    Let \(k = \min\{j : a'_{1,j} \neq 0\}\) and \(l = \max\{j : b'_{1, j} \neq 0\}\).
    I just need to show that \(l < k\).
    Suppose not.
    Then \((l - k)\) is nonnegative, and by \cref{ab_nilp} we have 
    \[0 = \sum_{ij} b_{ij}' a_{j - (l - k)}' = b_{1,l}' a_{1,k}' + \sum_{i' \geq 1, (i', j') \neq (1, \lambda_1)} b'_{ij} a'_{j - (l - k)}.\]
    This suggests defining 
    \[e_{1,\lambda_1}'' = b_{1, l}'e_{1, \lambda_1}' + \sum_{i' \geq 1, (i', j') \neq (1, \lambda_1)} b'_{i',j' - (\lambda_1 - l)} e'_{i'j'}.\]
    Then for \(j \leq k\),
    \[a_{1,j}'' = b'_{1, l} a'_{1, j} + \sum_{i' \geq 1, (i', j') \neq (1, \lambda_1)} b'_{i', j' - (\lambda_1 - l)} a'_{i', j' - (\lambda_1 - j)} = \]
    \[\sum_{i', j'} b'_{i', j' - (\lambda_1 - l)} a'_{i', j' - (\lambda_1 - j)} = \sum_{i', j'} b'_{i', j'} a'_{i', (j' + (\lambda_1 - l)) - (\lambda_1 - j)} = \sum_{i',j'} b'_{i',j'} a'_{i', j' - (l - j)}.\]
    This last thing is zero by \cref{ab_nilp}, using that \(l - j \geq 0\).
    But this contradicts the definition of the \(c_{i'j'}^1\), because we made it so that \((a''_{1, 1}, ..., a''_{1, k}) = 0\).
    
\end{proof}

\subsection{TODO}
\begin{itemize}
    \item Why are SOn flags what they are.
\end{itemize}

\bibliography{paper}
\end{document}
 